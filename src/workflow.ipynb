{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilities import read_s3_image_into_opencv, load_images, load_target_images, comparison_results_to_dataframe, smote_generator\n",
    "from modeling import rf_model\n",
    "from compare import ImageComparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from scipy.spatial.distance import cosine, hamming\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import boto3\n",
    "import botocore\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Establish S3 connection\n",
    "\n",
    "client = boto3.client('s3')\n",
    "resource = boto3.resource('s3')\n",
    "my_bucket = resource.Bucket('capstonedatag58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set parameters for image processing and model\n",
    "\n",
    "params = {'batch_size': 1000, 'sample_size': 1000, 'model_transform': {'grayscale': True, 'size': (96, 96),\n",
    "    'equalize': 'clahe'}, 'model_comparison': {'histogram': True, 'ssim': True, 'tweet_match': True, 'gradient_similarity': True}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieve target images and fit them to the comparison class\n",
    "\n",
    "targets, target_ids = load_target_images(my_bucket, 'harvey_scrape/images/target/', tweets=False)\n",
    "comp_obj = ImageComparison(**params['model_transform'], **params['model_comparison'])\n",
    "comp_obj.fit(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison results (sample): [(0.0029664426699144843, 0.053507480133024858, 0.10408548915347926, 0.23673420266454484), (0.3354133159123572, 0.081918019888014074, 0.22369025405752832, 0.090164747405265061), (0.4663453284016294, 0.025881410065369984, 0.10702851923084566, 0.32810080870703773), (-0.23331694102998718, 0.020202093788756224, 0.12397121585173046, 0.025338349724860078), (-0.19697545339778924, 0.013298164025733767, 0.1039577304161191, 0.19939154476481913)]\n",
      "Comparison results image IDs (sample): ['bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f']\n"
     ]
    }
   ],
   "source": [
    "#Collect images from the web scrape and compare them to the targets\n",
    "#Store the comparison results and their associated image ids\n",
    "tot_image_ids = []\n",
    "comparisons = []\n",
    "\n",
    "for images, image_ids in load_images(my_bucket, 'harvey_scrape/images/full/', params['batch_size'], params['sample_size']):\n",
    "    comp = comp_obj.compare(images)\n",
    "    tot_image_ids.extend(image_ids)\n",
    "    comparisons.extend(comp)\n",
    "\n",
    "tot_image_ids_per_comparison = [tot_image_ids[math.floor(i / len(target_ids))] for i in range(len(comparisons))]\n",
    "\n",
    "print('Comparison results (sample):', comparisons[0:5])\n",
    "print('Comparison results image IDs (sample):', tot_image_ids_per_comparison[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive image comparison results (sample): [(0.0029664426699144843, 0.053507480133024858, 0.10408548915347926, 0.23673420266454484), (0.3354133159123572, 0.081918019888014074, 0.22369025405752832, 0.090164747405265061), (0.4663453284016294, 0.025881410065369984, 0.10702851923084566, 0.32810080870703773), (-0.23331694102998718, 0.020202093788756224, 0.12397121585173046, 0.025338349724860078), (-0.19697545339778924, 0.013298164025733767, 0.1039577304161191, 0.19939154476481913)]\n",
      "True positive image comparison results image IDs (sample): ['bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f', 'bcf7e41e1ca491b7c576e212851f92398f29844f']\n"
     ]
    }
   ],
   "source": [
    "#Collect the true positive test images and compare them to trargets\n",
    "#Store the comparison results and the associated image ids.\n",
    "\n",
    "tps, tp_ids = load_target_images(my_bucket, 'harvey_scrape/images/test/', tweets=False)\n",
    "tp_comparisons = comp_obj.compare(tps)\n",
    "\n",
    "tp_comparisons_ids = []\n",
    "for item in tp_ids:\n",
    "    tp_comparisons_ids.extend([item] * len(targets))\n",
    "\n",
    "tp_comparisons_target_ids = []\n",
    "for i in range(int(len(tp_comparisons) / len(target_ids))):\n",
    "    tp_comparisons_target_ids.extend(target_ids)\n",
    "    \n",
    "print('True positive image comparison results (sample):', comparisons[0:5])\n",
    "print('True positive image comparison results image IDs (sample):', tot_image_ids_per_comparison[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/image_project/utilities.py:44: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  obs = tp_comparisons[np.random.randint(len(tp_comparisons), size=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Comparisons (sample): [[0.9078402928810405, 0.2366236515172559, 0.59241052506270364, 0.13609456431095321], [0.8468269704380365, 0.17294197855905119, 0.71305598612014465, 0.49509115122965469], [0.8525218236236112, 0.16021747086935867, 0.52375570037537722, 0.21530606708857739], [0.9106417536142489, 0.18334070269330527, 0.5680446976159651, 0.17637399187569591], [0.8830379435914336, 0.14190880754039342, 0.12682255484738378, 0.55128924206542529]]\n",
      "SMOTE Image IDs (sample): ['hh_gator_test3_smote_0', 'hh_obama_test4_smote_1', 'hh_dinosaur_test2_smote_2', 'hh_gator_test1_smote_3', 'hh_gator_test7_smote_4']\n",
      "SMOTE Target IDs (sample): ['hh_gator', 'hh_obama', 'hh_dinosaur', 'hh_gator', 'hh_gator_v2']\n",
      "Target IDs (sample): ['hh_airport', 'hh_cajun_navy', 'hh_dinosaur', 'hh_gator', 'hh_gator_v2']\n"
     ]
    }
   ],
   "source": [
    "#Select the true positive comparison results that are true matches using the image ids/labels\n",
    "#Store them in a dataframe and run SMOTE process to generate new synthetic observations\n",
    "\n",
    "tp_matches = [[x, y, z] for x, y, z in zip(tp_comparisons_ids, tp_comparisons_target_ids, tp_comparisons) if '_'.join(x.split('_')[0:2]) == '_'.join(y.split('_')[0:2])]\n",
    "\n",
    "tp_df = pd.DataFrame(data=tp_matches, columns=['image', 'target', 'comparison'])\n",
    "\n",
    "smote_comparisons, smote_image_ids, smote_target_ids = smote_generator(comparisons, tp_df, threshold=.1)\n",
    "\n",
    "target_ids_full = []\n",
    "for i in range(len(tot_image_ids)):\n",
    "    target_ids_full.extend(target_ids)\n",
    "\n",
    "print('SMOTE Comparisons (sample):', smote_comparisons[0:5])\n",
    "print('SMOTE Image IDs (sample):', smote_image_ids[0:5])\n",
    "print('SMOTE Target IDs (sample):', smote_target_ids[0:5])\n",
    "print('Target IDs (sample):', target_ids[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>target</th>\n",
       "      <th>histogram</th>\n",
       "      <th>ssim</th>\n",
       "      <th>tweet_match</th>\n",
       "      <th>gradient_similarity</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bcf7e41e1ca491b7c576e212851f92398f29844f</td>\n",
       "      <td>hh_airport</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.053507</td>\n",
       "      <td>0.104085</td>\n",
       "      <td>0.236734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcf7e41e1ca491b7c576e212851f92398f29844f</td>\n",
       "      <td>hh_cajun_navy</td>\n",
       "      <td>0.335413</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>0.223690</td>\n",
       "      <td>0.090165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bcf7e41e1ca491b7c576e212851f92398f29844f</td>\n",
       "      <td>hh_dinosaur</td>\n",
       "      <td>0.466345</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.328101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bcf7e41e1ca491b7c576e212851f92398f29844f</td>\n",
       "      <td>hh_gator</td>\n",
       "      <td>-0.233317</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.123971</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcf7e41e1ca491b7c576e212851f92398f29844f</td>\n",
       "      <td>hh_gator_v2</td>\n",
       "      <td>-0.196975</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>0.103958</td>\n",
       "      <td>0.199392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image         target  histogram  \\\n",
       "0  bcf7e41e1ca491b7c576e212851f92398f29844f     hh_airport   0.002966   \n",
       "1  bcf7e41e1ca491b7c576e212851f92398f29844f  hh_cajun_navy   0.335413   \n",
       "2  bcf7e41e1ca491b7c576e212851f92398f29844f    hh_dinosaur   0.466345   \n",
       "3  bcf7e41e1ca491b7c576e212851f92398f29844f       hh_gator  -0.233317   \n",
       "4  bcf7e41e1ca491b7c576e212851f92398f29844f    hh_gator_v2  -0.196975   \n",
       "\n",
       "       ssim  tweet_match  gradient_similarity  matches  \n",
       "0  0.053507     0.104085             0.236734        0  \n",
       "1  0.081918     0.223690             0.090165        0  \n",
       "2  0.025881     0.107029             0.328101        0  \n",
       "3  0.020202     0.123971             0.025338        0  \n",
       "4  0.013298     0.103958             0.199392        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put image and true positive image comparison results into a pandas dataframe\n",
    "\n",
    "df = comparison_results_to_dataframe(comparisons, tot_image_ids_per_comparison, target_ids_full)\n",
    "df_smote = comparison_results_to_dataframe(smote_comparisons, smote_image_ids, smote_target_ids)\n",
    "df = df.append(df_smote)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model recall: 0.933333333333\n",
      "Model precision: 0.973913043478\n",
      "Model feature importances: [ 0.599908    0.14003671  0.22607083  0.03398446]\n"
     ]
    }
   ],
   "source": [
    "#Run the Random Forest model to predict classifications\n",
    "\n",
    "rf_pred, rf_recall, rf_precision, rf_feature_importances = rf_model(df, 96, 3, 4)\n",
    "\n",
    "print('Model recall:', rf_recall)\n",
    "print('Model precision:', rf_precision)\n",
    "print('Model feature importances:', rf_feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
